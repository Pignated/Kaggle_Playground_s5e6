import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV


df = pd.read_csv("train.csv",index_col=0)


from sklearn.metrics import make_scorer
sample = pd.read_csv("sample_submission.csv",index_col=0)
test = pd.read_csv("test.csv",index_col=0)
sample
def in_top_three_scoring(y_true, y_proba):
    top_3_indices = np.flip(np.argsort(y_proba, axis=1)[:, -3:], axis=1)
    accurate_counts = 0
    for i, val in enumerate(y_true):
        if val in top_3_indices[i]:
            accurate_counts += 1
    return accurate_counts / len(y_true)
top_three_scorer = lambda estimator, X, y : in_top_three_scoring(y, estimator.predict_proba(X))
def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)
def predict_test_values(estimator):
    y_test_pred = estimator.predict_proba(test)
    y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
    y_test_pred_strings = vectorized_mapper(y_test_pred_top3)
    aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
    return aaa
fert_encoder = LabelEncoder()
X = df.drop(columns=['Fertilizer Name'])
y=fert_encoder.fit_transform(df['Fertilizer Name'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=42)
preprocessor = make_column_transformer((StandardScaler(),("Temparature","Humidity","Moisture","Nitrogen","Potassium","Phosphorous")),(OneHotEncoder(),("Soil Type","Crop Type")))


param_grid = {
    'gb__n_estimators': [50, 100, 200],
    'gb__learning_rate': [0.01, 0.1, 0.2],
    'gb__max_depth': [3, 5, 7],
    'gb__subsample': [0.8, 1.0]
}

fert_encoder = LabelEncoder()
X = df.drop(columns=['Fertilizer Name'])
y=fert_encoder.fit_transform(df['Fertilizer Name'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=42)
preprocessor = make_column_transformer((StandardScaler(),("Temparature","Humidity","Moisture","Nitrogen","Potassium","Phosphorous")),(OneHotEncoder(),("Soil Type","Crop Type")))
GB_OHE = Pipeline([('proc',preprocessor),('gb',GradientBoostingClassifier())])
grid_search_gb = RandomizedSearchCV(GB_OHE, param_grid, cv=5, scoring=top_three_scorer, n_jobs=5,verbose=2)
# Use this to test ^ before running full grid search
# grid_search_gb = GridSearchCV(GB_OHE, param_grid, cv=5, scoring=top_three_scorer, n_jobs=5,verbose=2)
grid_search_gb.fit(X,y)







grid_gb = grid_search_gb.best_estimator_
print(grid_gb.get_params())
# print(grid_search_gb.best_score_)
best_score_gb = make_pipeline(('proc',preprocessor),('gb',GradientBoostingClassifier(verbose=1)))
best_score_gb.set_params(**grid_gb.get_params())
best_score_gb.fit(X_train,y_train)
y_pred = SGD_OHE.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)
print(y_pred)
print(in_top_three_scoring(y_test,y_pred))
best_score_gb.fit(X,y)
sample['Fertilizer Name'] = predict_test_values(best_score_gb)





from xgboost import XGBClassifier
param_grid = {
    'gb__n_estimators': [50, 100, 200],
    'gb__learning_rate': [0.01, 0.1, 0.2],
    'gb__max_depth': [3, 5, 7],
    'gb__subsample': [0.8, 1.0]
}
xgb_pipeline =  Pipeline([('proc',preprocessor),('gb',XGBClassifier())])
grid_search_xgb = GridSearchCV(xgb_pipeline, param_grid, cv=5, scoring=top_three_scorer, n_jobs=5,verbose=2)
grid_search_xgb.fit(X,y)


from xgboost import XGBClassifier
param_grid = {
    'gb__n_estimators': [50, 100, 200],
    'gb__learning_rate': [0.01, 0.1, 0.2],
    'gb__max_depth': [3, 5, 7],
    'gb__subsample': [0.8, 1.0]
}
xgb_pipeline =  Pipeline([('proc',preprocessor),('gb',XGBClassifier())])
rand_search_xgb = RandomizedSearchCV(xgb_pipeline, param_grid, cv=5, scoring=top_three_scorer, n_jobs=1,verbose=2)
rand_search_xgb.fit(X,y)


rand_search_xgb.best_params_


xgb_rand_best = rand_search_xgb.best_estimator_
xgb_rand_best.fit(X_train,y_train)
in_top_three_scoring(y_test,xgb_rand_best.predict_proba(X_test))


xgb_rand_best.fit(X,y)



in_top_three_scoring(y,xgb_rand_best.predict_proba(X))


out = predict_test_values(xgb_rand_best)
out[1]


y_test_pred = xgb_rand_best.predict_proba(test)
y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
y_test_pred_strings = vectorized_mapper(y_test_pred_top3)
aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
aaa



def predict_test_values(estimator):
    y_test_pred = estimator.predict_proba(test)
    y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
    y_test_pred_strings = vectorized_mapper(y_test_pred_top3).astype(object)
    aaa=[]
    for val in y_test_pred_strings:
        aaa.append(" ".join(val))
    return aaa


sample['Fertilizer Name'] = predict_test_values(xgb_rand_best)
sample


sample.to_csv("attempt3.csv")
