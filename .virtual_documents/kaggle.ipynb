import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split


df = pd.read_csv("train.csv",index_col=0)


df.head()


from sklearn.preprocessing import LabelEncoder
fert_encoder = LabelEncoder()
soil_encoder = LabelEncoder()
crop_encoder = LabelEncoder()
encoded_df = df.copy()
encoded_df['Fertilizer Name'] = fert_encoder.fit_transform(encoded_df['Fertilizer Name'])
encoded_df['Soil Type'] = soil_encoder.fit_transform(encoded_df['Soil Type'])
encoded_df['Crop Type'] = crop_encoder.fit_transform(encoded_df['Crop Type'])
X = encoded_df.drop(['Fertilizer Name'], axis=1)
y = encoded_df['Fertilizer Name']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


df.head()


encoded_df.head()


from sklearn.tree import DecisionTreeClassifier
clf = AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_leaf_nodes=14),
    n_estimators=300,
    random_state=42
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy of AdaBoost Classifier:", accuracy_score(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)


from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(
    random_state=42
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy of Random Forest Classifier:", accuracy_score(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)


from sklearn.dummy import DummyClassifier
dummy_clf = DummyClassifier(strategy='most_frequent')
dummy_clf.fit(X_train, y_train)
dummy_y_pred = dummy_clf.predict(X)
print("Accuracy of Dummy Classifier:", accuracy_score(y, dummy_y_pred))
# Plotting the confusion matrix for the dummy classifier
dummy_cm = confusion_matrix(y, dummy_y_pred)
sns.heatmap(dummy_cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)
plt.figure(figsize=(8, 6))


from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss'))
SGD_clf.fit(X_train, y_train)
y_pred = SGD_clf.predict(X_test)
print("Accuracy of SGD Classifier:", accuracy_score(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)

##USE GridSearchCV to find alpha



prob_predictions = SGD_clf.predict_proba(X)
top_3_indices = np.flip(np.argsort(prob_predictions, axis=1)[:, -3:],axis=1)
top_3_indices
accurate_counts=0
for i, val in enumerate(y):
    if val in top_3_indices[i]:
        accurate_counts += 1
print(accurate_counts/len(y))


print(y_pred)
print(top_3_indices)


from sklearn.metrics import make_scorer
def in_top_three_scoring(y_true, y_proba):
    top_3_indices = np.flip(np.argsort(y_proba, axis=1)[:, -3:], axis=1)
    accurate_counts = 0
    for i, val in enumerate(y_true):
        if val in top_3_indices[i]:
            accurate_counts += 1
    return accurate_counts / len(y_true)
top_three_scorer = lambda estimator, X, y : in_top_three_scoring(y, estimator.predict_proba(X))



from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
param_grid = {
    'sgdclassifier__alpha': 10.0**-np.arange(1,7),
    'sgdclassifier__max_iter': [1000, 2000, 3000]
}
SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000))
grid_search = GridSearchCV(SGD_clf, param_grid, cv=5, scoring=top_three_scorer, n_jobs=-1)
grid_search.fit(X, y)
print("Best parameters found: ", grid_search.best_params_)



SGD_clf_ada = make_pipeline(StandardScaler(),AdaBoostClassifier(estimator=SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000,verbose=True),n_estimators=500))
SGD_clf_ada.fit(X,y)






SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000))
SGD_clf.fit(X,y)


y_pred = SGD_clf.predict_proba(X)
in_top_three_scoring(y,y_pred)


sample = pd.read_csv("sample_submission.csv",index_col=0)
test = pd.read_csv("test.csv",index_col=0)
sample


test['Soil Type'] = soil_encoder.transform(test['Soil Type'])
test['Crop Type'] = crop_encoder.transform(test['Crop Type'])
test


y_test_pred = SGD_clf.predict_proba(test)


def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)


y_test_pred
y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
y_test_pred_top3
y_test_pred_strings = vectorized_mapper(y_test_pred_top3)




aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
aaa


sample['Fertilizer Name']= aaa



vectorized_mapper(np.flip(np.argsort(SGD_clf.predict_proba(test.iloc[:2]), axis=1)[:, -3:], axis=1))


sample.to_csv("attempt1.csv")
