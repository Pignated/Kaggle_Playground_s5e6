import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split


df = pd.read_csv("train.csv",index_col=0)


df.head()


from sklearn.preprocessing import LabelEncoder
fert_encoder = LabelEncoder()
soil_encoder = LabelEncoder()
crop_encoder = LabelEncoder()
encoded_df = df.copy()
encoded_df['Fertilizer Name'] = fert_encoder.fit_transform(encoded_df['Fertilizer Name'])
encoded_df['Soil Type'] = soil_encoder.fit_transform(encoded_df['Soil Type'])
encoded_df['Crop Type'] = crop_encoder.fit_transform(encoded_df['Crop Type'])
X = encoded_df.drop(['Fertilizer Name'], axis=1)
y = encoded_df[['Fertilizer Name']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


type(y_test)


df.head()


encoded_df.head()


from sklearn.tree import DecisionTreeClassifier
clf = AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_leaf_nodes=14),
    n_estimators=300,
    random_state=42
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy of AdaBoost Classifier:", accuracy_score(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)


from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(
    random_state=42
)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy of Random Forest Classifier:", accuracy_score(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)


from sklearn.dummy import DummyClassifier
dummy_clf = DummyClassifier(strategy='most_frequent')
dummy_clf.fit(X_train, y_train)
dummy_y_pred = dummy_clf.predict(X)
print("Accuracy of Dummy Classifier:", accuracy_score(y, dummy_y_pred))
# Plotting the confusion matrix for the dummy classifier
dummy_cm = confusion_matrix(y, dummy_y_pred)
sns.heatmap(dummy_cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)
plt.figure(figsize=(8, 6))


from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss'))
SGD_clf.fit(X_train, y_train)
y_pred = SGD_clf.predict(X_test)
print("Accuracy of SGD Classifier:", accuracy_score(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)

##USE GridSearchCV to find alpha



prob_predictions = SGD_clf.predict_proba(X)
top_3_indices = np.flip(np.argsort(prob_predictions, axis=1)[:, -3:],axis=1)
top_3_indices
accurate_counts=0
for i, val in enumerate(y):
    if val in top_3_indices[i]:
        accurate_counts += 1
print(accurate_counts/len(y))


print(y_pred)
print(top_3_indices)


from sklearn.metrics import make_scorer
def in_top_three_scoring(y_true, y_proba):
    top_3_indices = np.flip(np.argsort(y_proba, axis=1)[:, -3:], axis=1)
    accurate_counts = 0
    for i, val in enumerate(y_true):
        if val in top_3_indices[i]:
            accurate_counts += 1
    return accurate_counts / len(y_true)
top_three_scorer = lambda estimator, X, y : in_top_three_scoring(y, estimator.predict_proba(X))



from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
param_grid = {
    'sgdclassifier__alpha': 10.0**-np.arange(1,7),
    'sgdclassifier__max_iter': [1000, 2000, 3000]
}
SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss'))
grid_search = GridSearchCV(SGD_clf, param_grid, cv=5, scoring=top_three_scorer, n_jobs=-1,verbose=True)
grid_search.fit(X, y)
print("Best parameters found: ", grid_search.best_params_)



%%time
SGD_clf_best_params = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=3000))
SGD_clf_best_params.fit(X_train,y_train)
y_pred = SGD_clf_best_params.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)





%%time
SGD_clf_ada = make_pipeline(StandardScaler(),AdaBoostClassifier(n_estimators=500))
SGD_clf_ada.fit(X_train,y_train)
y_pred = SGD_clf_ada.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)


SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000))
SGD_clf.fit(X_train,y_train)


y_pred = SGD_clf.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)


sample = pd.read_csv("sample_submission.csv",index_col=0)
test = pd.read_csv("test.csv",index_col=0)
sample


test['Soil Type'] = soil_encoder.transform(test['Soil Type'])
test['Crop Type'] = crop_encoder.transform(test['Crop Type'])
test


y_test_pred = SGD_clf.predict_proba(test)


def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)


y_test_pred = SGD_clf.predict_proba(test)

y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)
y_test_pred_strings = vectorized_mapper(y_test_pred_top3)
aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)



aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
aaa


sample['Fertilizer Name']= aaa



vectorized_mapper(np.flip(np.argsort(SGD_clf.predict_proba(test.iloc[:2]), axis=1)[:, -3:], axis=1))


sample.to_csv("attempt1.csv")






from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
fert_encoder = LabelEncoder()
X = df.drop(columns=['Fertilizer Name'])
y=fert_encoder.fit_transform(df['Fertilizer Name'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=42)
num_preprocessing = make_pipeline(StandardScaler())
preprocessor = make_column_transformer((StandardScaler(),("Temparature","Humidity","Moisture","Nitrogen","Potassium","Phosphorous")),(OneHotEncoder(),("Soil Type","Crop Type")))
SGD_OHE = make_pipeline(preprocessor,SGDClassifier(loss='log_loss', alpha=.01,max_iter=3000))
SGD_OHE.fit(X_train,y_train)
y_pred = SGD_OHE.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)
print(y_pred)
print(in_top_three_scoring(y_test,y_pred))



from sklearn.ensemble import GradientBoostingClassifier
fert_encoder = LabelEncoder()
X = df.drop(columns=['Fertilizer Name'])
y=fert_encoder.fit_transform(df['Fertilizer Name'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=42)
num_preprocessing = make_pipeline(StandardScaler())
preprocessor = make_column_transformer((StandardScaler(),("Temparature","Humidity","Moisture","Nitrogen","Potassium","Phosphorous")),(OneHotEncoder(),("Soil Type","Crop Type")))
SGD_OHE = make_pipeline(preprocessor,GradientBoostingClassifier(loss='log_loss',verbose=1))
SGD_OHE.fit(X_train,y_train)
y_pred = SGD_OHE.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)
print(y_pred)
print(in_top_three_scoring(y_test,y_pred))



def in_top_three_scoring(y_true, y_proba):
    top_3_indices = np.flip(np.argsort(y_proba, axis=1)[:, -3:], axis=1)
    accurate_counts = 0
    for i, val in enumerate(y_true):
        if val in top_3_indices[i]:
            accurate_counts += 1
    return accurate_counts / len(y_true)
print(np.flip(np.argsort(y_pred, axis=1)[:, -3:], axis=1))


sample = pd.read_csv("sample_submission.csv",index_col=0)
test = pd.read_csv("test.csv",index_col=0)
y_test_pred = SGD_OHE.predict_proba(test)
y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)
y_test_pred_strings = vectorized_mapper(y_test_pred_top3)
aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
sample['Fertilizer Name'] = aaa
sample
sample.to_csv("attempt2.csv")


param_grid = {
    'gb__loss':['log_loss','exponential'],
    'gb__n_estimators': [50, 100, 200],
    'gb__learning_rate': [0.01, 0.1, 0.2],
    'gb__max_depth': [3, 5, 7],
    'gb__subsample': [0.8, 1.0]
}
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.model_selection import GridSearchCV
fert_encoder = LabelEncoder()
X = df.drop(columns=['Fertilizer Name'])
y=fert_encoder.fit_transform(df['Fertilizer Name'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2,random_state=42)
preprocessor = make_column_transformer((StandardScaler(),("Temparature","Humidity","Moisture","Nitrogen","Potassium","Phosphorous")),(OneHotEncoder(),("Soil Type","Crop Type")))
GB_OHE = Pipeline([('proc',preprocessor),('gb',GradientBoostingClassifier())])
grid_search_gb = GridSearchCV(GB_OHE, param_grid, cv=5, scoring=top_three_scorer, n_jobs=5,verbose=1)
grid_search_gb.fit(X,y)




grid_gb = grid_search.best_estimator_
print(grid_gb.best_params_)
print(grid_gb.best_score_)
best_score_gb = make_pipeline(('proc',preprocessor),('gb',GradientBoostingClassifier(verbose=1)))
best_score_gb.set_params(**grid_gb.best_params_)
best_score_gb.fit(X_train,y_train)
y_pred = SGD_OHE.predict_proba(X_test)
in_top_three_scoring(y_test,y_pred)
print(y_pred)
print(in_top_three_scoring(y_test,y_pred))
best_score_gb.fit(X,y)
y_test_pred = best_score_gb.predict_proba(test)
y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)
def mapper(x):
    return fert_encoder.classes_[x]
vectorized_mapper = np.vectorize(mapper)
y_test_pred_strings = vectorized_mapper(y_test_pred_top3)
aaa = np.apply_along_axis(" ".join, arr=y_test_pred_strings, axis=1)
