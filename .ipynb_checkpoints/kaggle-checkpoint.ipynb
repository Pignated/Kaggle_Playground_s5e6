{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ae692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3167eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651700e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c2785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "fert_encoder = LabelEncoder()\n",
    "soil_encoder = LabelEncoder()\n",
    "crop_encoder = LabelEncoder()\n",
    "encoded_df = df.copy()\n",
    "encoded_df['Fertilizer Name'] = fert_encoder.fit_transform(encoded_df['Fertilizer Name'])\n",
    "encoded_df['Soil Type'] = soil_encoder.fit_transform(encoded_df['Soil Type'])\n",
    "encoded_df['Crop Type'] = crop_encoder.fit_transform(encoded_df['Crop Type'])\n",
    "X = encoded_df.drop(['Fertilizer Name'], axis=1)\n",
    "y = encoded_df['Fertilizer Name']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f17e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Crop Type</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphorous</th>\n",
       "      <th>Fertilizer Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>Clayey</td>\n",
       "      <td>Sugarcane</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>28-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Millets</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>28-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Millets</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17-17-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>Sandy</td>\n",
       "      <td>Barley</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10-26-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>Red</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>DAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temparature  Humidity  Moisture Soil Type  Crop Type  Nitrogen  Potassium  \\\n",
       "id                                                                              \n",
       "0            37        70        36    Clayey  Sugarcane        36          4   \n",
       "1            27        69        65     Sandy    Millets        30          6   \n",
       "2            29        63        32     Sandy    Millets        24         12   \n",
       "3            35        62        54     Sandy     Barley        39         12   \n",
       "4            35        58        43       Red      Paddy        37          2   \n",
       "\n",
       "    Phosphorous Fertilizer Name  \n",
       "id                               \n",
       "0             5           28-28  \n",
       "1            18           28-28  \n",
       "2            16        17-17-17  \n",
       "3             4        10-26-26  \n",
       "4            16             DAP  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "814140aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Crop Type</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphorous</th>\n",
       "      <th>Fertilizer Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temparature  Humidity  Moisture  Soil Type  Crop Type  Nitrogen  \\\n",
       "id                                                                    \n",
       "0            37        70        36          1          8        36   \n",
       "1            27        69        65          4          4        30   \n",
       "2            29        63        32          4          4        24   \n",
       "3            35        62        54          4          0        39   \n",
       "4            35        58        43          3          6        37   \n",
       "\n",
       "    Potassium  Phosphorous  Fertilizer Name  \n",
       "id                                           \n",
       "0           4            5                4  \n",
       "1           6           18                4  \n",
       "2          12           16                2  \n",
       "3          12            4                0  \n",
       "4           2           16                5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_leaf_nodes=14),\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy of AdaBoost Classifier:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c14fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy of Random Forest Classifier:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_y_pred = dummy_clf.predict(X)\n",
    "print(\"Accuracy of Dummy Classifier:\", accuracy_score(y, dummy_y_pred))\n",
    "# Plotting the confusion matrix for the dummy classifier\n",
    "dummy_cm = confusion_matrix(y, dummy_y_pred)\n",
    "sns.heatmap(dummy_cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)\n",
    "plt.figure(figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19aa429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss'))\n",
    "SGD_clf.fit(X_train, y_train)\n",
    "y_pred = SGD_clf.predict(X_test)\n",
    "print(\"Accuracy of SGD Classifier:\", accuracy_score(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=fert_encoder.classes_, yticklabels=fert_encoder.classes_)\n",
    "\n",
    "##USE GridSearchCV to find alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e45812",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_predictions = SGD_clf.predict_proba(X)\n",
    "top_3_indices = np.flip(np.argsort(prob_predictions, axis=1)[:, -3:],axis=1)\n",
    "top_3_indices\n",
    "accurate_counts=0\n",
    "for i, val in enumerate(y):\n",
    "    if val in top_3_indices[i]:\n",
    "        accurate_counts += 1\n",
    "print(accurate_counts/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "print(top_3_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04938ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def in_top_three_scoring(y_true, y_proba):\n",
    "    top_3_indices = np.flip(np.argsort(y_proba, axis=1)[:, -3:], axis=1)\n",
    "    accurate_counts = 0\n",
    "    for i, val in enumerate(y_true):\n",
    "        if val in top_3_indices[i]:\n",
    "            accurate_counts += 1\n",
    "    return accurate_counts / len(y_true)\n",
    "top_three_scorer = lambda estimator, X, y : in_top_three_scoring(y, estimator.predict_proba(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d3bf4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m SGD_clf \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(),SGDClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     10\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(SGD_clf, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mtop_three_scorer, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "param_grid = {\n",
    "    'sgdclassifier__alpha': 10.0**-np.arange(1,7),\n",
    "    'sgdclassifier__max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000))\n",
    "grid_search = GridSearchCV(SGD_clf, param_grid, cv=5, scoring=top_three_scorer, n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7ea96ff-ca0e-40b6-8dcf-891709f89f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan.Cobb\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.34 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.64 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.33 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000465, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.61 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.34 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.40 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 750000, Avg. loss: 0.692973\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 2250000, Avg. loss: 0.692938\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000595, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000604, T: 4500000, Avg. loss: 0.692923\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000589, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000598, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.76 seconds.\n",
      "Convergence after 6 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.49 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 750000, Avg. loss: 0.692991\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 1500000, Avg. loss: 0.692969\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 2250000, Avg. loss: 0.692960\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3000000, Avg. loss: 0.692954\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 3750000, Avg. loss: 0.692950\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 4500000, Avg. loss: 0.692947\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000589, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000598, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 2250000, Avg. loss: 0.692938\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000599, T: 4500000, Avg. loss: 0.692923\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 6 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 6 epochs took 1.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000460, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000493, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.88 seconds.\n",
      "Convergence after 6 epochs took 1.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000482, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.33 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.35 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 6 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000601, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.34 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000595, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.39 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000477, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000455, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 2250000, Avg. loss: 0.692975\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 4500000, Avg. loss: 0.692962\n",
      "Total training time: 2.20 seconds.\n",
      "Convergence after 6 epochs took 2.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 2250000, Avg. loss: 0.692938\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000580, T: 3000000, Avg. loss: 0.692931\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 3750000, Avg. loss: 0.692926\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000600, T: 4500000, Avg. loss: 0.692923\n",
      "Total training time: 1.25 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 6 epochs took 1.36 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.73 seconds.\n",
      "Convergence after 6 epochs took 1.73 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.50 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000494, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000572, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.64 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 2.05 seconds.\n",
      "Convergence after 6 epochs took 2.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000577, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 2.16 seconds.\n",
      "Convergence after 6 epochs took 2.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000453, T: 750000, Avg. loss: 0.693006\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 2250000, Avg. loss: 0.692975\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 4500000, Avg. loss: 0.692962\n",
      "Total training time: 1.39 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000451, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.92 seconds.\n",
      "Convergence after 6 epochs took 1.92 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000572, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.88 seconds.\n",
      "Convergence after 6 epochs took 1.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 2.88 seconds.\n",
      "Convergence after 6 epochs took 2.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000456, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000488, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 2.12 seconds.\n",
      "Convergence after 6 epochs took 2.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 750000, Avg. loss: 0.692991\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 1500000, Avg. loss: 0.692968\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 2250000, Avg. loss: 0.692959\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3000000, Avg. loss: 0.692954\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 3750000, Avg. loss: 0.692950\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 4500000, Avg. loss: 0.692946\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 1500000, Avg. loss: 0.692954\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 2250000, Avg. loss: 0.692944\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 3000000, Avg. loss: 0.692938\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3750000, Avg. loss: 0.692933\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 4500000, Avg. loss: 0.692929\n",
      "Total training time: 1.83 seconds.\n",
      "Convergence after 6 epochs took 1.83 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 750000, Avg. loss: 0.692971\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 1500000, Avg. loss: 0.692945\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 2250000, Avg. loss: 0.692935\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3000000, Avg. loss: 0.692928\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000599, T: 3750000, Avg. loss: 0.692924\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000608, T: 4500000, Avg. loss: 0.692920\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000454, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 2250000, Avg. loss: 0.692975\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 4500000, Avg. loss: 0.692962\n",
      "Total training time: 1.58 seconds.\n",
      "Convergence after 6 epochs took 1.58 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.79 seconds.\n",
      "Convergence after 6 epochs took 1.79 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.14 seconds.\n",
      "Convergence after 6 epochs took 2.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.40 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.69 seconds.\n",
      "Convergence after 6 epochs took 1.69 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 750000, Avg. loss: 0.692984\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692959\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 2250000, Avg. loss: 0.692949\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 3000000, Avg. loss: 0.692943\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 3750000, Avg. loss: 0.692938\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 4500000, Avg. loss: 0.692934\n",
      "Total training time: 2.24 seconds.\n",
      "Convergence after 6 epochs took 2.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 750000, Avg. loss: 0.692972\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 1500000, Avg. loss: 0.692946\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 2250000, Avg. loss: 0.692936\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3000000, Avg. loss: 0.692930\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000595, T: 3750000, Avg. loss: 0.692925\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000604, T: 4500000, Avg. loss: 0.692921\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 6 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000492, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000453, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.43 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.27 seconds.\n",
      "Convergence after 6 epochs took 1.27 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692987\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692961\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 2250000, Avg. loss: 0.692951\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3000000, Avg. loss: 0.692945\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 3750000, Avg. loss: 0.692940\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 4500000, Avg. loss: 0.692937\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 2.22 seconds.\n",
      "Convergence after 6 epochs took 2.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.75 seconds.\n",
      "Convergence after 6 epochs took 1.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000446, T: 750000, Avg. loss: 0.693008\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 1500000, Avg. loss: 0.692986\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 2250000, Avg. loss: 0.692977\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 3000000, Avg. loss: 0.692972\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3750000, Avg. loss: 0.692968\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 4500000, Avg. loss: 0.692965\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000483, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000488, T: 750000, Avg. loss: 0.692992\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692969\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3000000, Avg. loss: 0.692955\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000572, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 750000, Avg. loss: 0.692980\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 1500000, Avg. loss: 0.692954\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 2250000, Avg. loss: 0.692944\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 3000000, Avg. loss: 0.692938\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3750000, Avg. loss: 0.692933\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 4500000, Avg. loss: 0.692929\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000577, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000598, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.10 seconds.\n",
      "Convergence after 6 epochs took 1.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000465, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000599, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.09 seconds.\n",
      "Convergence after 6 epochs took 1.09 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000572, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 2.30 seconds.\n",
      "Convergence after 6 epochs took 2.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000480, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.25 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000602, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000603, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000595, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.15 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000456, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000482, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.27 seconds.\n",
      "Convergence after 6 epochs took 1.27 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 750000, Avg. loss: 0.692981\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 1500000, Avg. loss: 0.692955\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 2250000, Avg. loss: 0.692945\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 3000000, Avg. loss: 0.692939\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 3750000, Avg. loss: 0.692934\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 4500000, Avg. loss: 0.692931\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000580, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000589, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000454, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.10 seconds.\n",
      "Convergence after 6 epochs took 1.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 6 epochs took 1.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000482, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.43 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000595, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.35 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000496, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000577, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 2.13 seconds.\n",
      "Convergence after 6 epochs took 2.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 2.89 seconds.\n",
      "Convergence after 6 epochs took 2.89 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 750000, Avg. loss: 0.692981\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 1500000, Avg. loss: 0.692955\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 2250000, Avg. loss: 0.692945\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 3000000, Avg. loss: 0.692939\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 3750000, Avg. loss: 0.692934\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 4500000, Avg. loss: 0.692931\n",
      "Total training time: 2.27 seconds.\n",
      "Convergence after 6 epochs took 2.27 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 6 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.15 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 6 epochs took 1.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000477, T: 750000, Avg. loss: 0.692988\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692962\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 2250000, Avg. loss: 0.692952\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3000000, Avg. loss: 0.692946\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 3750000, Avg. loss: 0.692941\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 4500000, Avg. loss: 0.692938\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000575, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.73 seconds.\n",
      "Convergence after 6 epochs took 2.73 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.75 seconds.\n",
      "Convergence after 6 epochs took 2.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000477, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 2.14 seconds.\n",
      "Convergence after 6 epochs took 2.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3000000, Avg. loss: 0.692955\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 1.95 seconds.\n",
      "Convergence after 6 epochs took 1.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 2.13 seconds.\n",
      "Convergence after 6 epochs took 2.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 2.56 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 3.13 seconds.\n",
      "Convergence after 6 epochs took 3.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 750000, Avg. loss: 0.692972\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 1500000, Avg. loss: 0.692945\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 2250000, Avg. loss: 0.692936\n",
      "Total training time: 2.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 3000000, Avg. loss: 0.692929\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000597, T: 3750000, Avg. loss: 0.692924\n",
      "Total training time: 3.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000606, T: 4500000, Avg. loss: 0.692921\n",
      "Total training time: 3.59 seconds.\n",
      "Convergence after 6 epochs took 3.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000494, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 2.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 3.21 seconds.\n",
      "Convergence after 6 epochs took 3.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000447, T: 750000, Avg. loss: 0.693007\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 1500000, Avg. loss: 0.692985\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 2250000, Avg. loss: 0.692976\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 3000000, Avg. loss: 0.692970\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 3750000, Avg. loss: 0.692966\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 4500000, Avg. loss: 0.692963\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 2.29 seconds.\n",
      "Convergence after 6 epochs took 2.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000464, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000496, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 750000, Avg. loss: 0.692980\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 1500000, Avg. loss: 0.692955\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 2250000, Avg. loss: 0.692945\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 3000000, Avg. loss: 0.692938\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000577, T: 3750000, Avg. loss: 0.692934\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 4500000, Avg. loss: 0.692930\n",
      "Total training time: 2.15 seconds.\n",
      "Convergence after 6 epochs took 2.15 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 750000, Avg. loss: 0.692972\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 1500000, Avg. loss: 0.692945\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 2250000, Avg. loss: 0.692935\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000586, T: 3000000, Avg. loss: 0.692929\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000597, T: 3750000, Avg. loss: 0.692924\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000606, T: 4500000, Avg. loss: 0.692920\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.40 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 2.58 seconds.\n",
      "Convergence after 6 epochs took 2.58 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000460, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000493, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 3.95 seconds.\n",
      "Convergence after 6 epochs took 3.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000460, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000492, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.28 seconds.\n",
      "Convergence after 6 epochs took 2.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.28 seconds.\n",
      "Convergence after 6 epochs took 1.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.24 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000466, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000454, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 6 epochs took 1.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 2.15 seconds.\n",
      "Convergence after 6 epochs took 2.15 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000464, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000453, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.40 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000467, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000518, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 750000, Avg. loss: 0.692992\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692969\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3000000, Avg. loss: 0.692955\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 1.17 seconds.\n",
      "Convergence after 6 epochs took 1.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000451, T: 750000, Avg. loss: 0.693006\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 1500000, Avg. loss: 0.692984\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 2250000, Avg. loss: 0.692975\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 3000000, Avg. loss: 0.692970\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 3750000, Avg. loss: 0.692966\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 4500000, Avg. loss: 0.692963\n",
      "Total training time: 1.39 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000454, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000486, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 2250000, Avg. loss: 0.692975\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 4500000, Avg. loss: 0.692962\n",
      "Total training time: 1.87 seconds.\n",
      "Convergence after 6 epochs took 1.87 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 2.46 seconds.\n",
      "Convergence after 6 epochs took 2.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 2.78 seconds.\n",
      "Convergence after 6 epochs took 2.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000465, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 2.23 seconds.\n",
      "Convergence after 6 epochs took 2.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 2.17 seconds.\n",
      "Convergence after 6 epochs took 2.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 750000, Avg. loss: 0.692972\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 1500000, Avg. loss: 0.692946\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 2250000, Avg. loss: 0.692936\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3000000, Avg. loss: 0.692929\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 3750000, Avg. loss: 0.692925\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000605, T: 4500000, Avg. loss: 0.692921\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.80 seconds.\n",
      "Convergence after 6 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000464, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000496, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.91 seconds.\n",
      "Convergence after 6 epochs took 1.91 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.95 seconds.\n",
      "Convergence after 6 epochs took 1.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 750000, Avg. loss: 0.692973\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 1500000, Avg. loss: 0.692946\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 2250000, Avg. loss: 0.692936\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3000000, Avg. loss: 0.692930\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 3750000, Avg. loss: 0.692925\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000603, T: 4500000, Avg. loss: 0.692921\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000474, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 750000, Avg. loss: 0.692970\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 1500000, Avg. loss: 0.692945\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 2250000, Avg. loss: 0.692935\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 3000000, Avg. loss: 0.692929\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000603, T: 3750000, Avg. loss: 0.692924\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000612, T: 4500000, Avg. loss: 0.692920\n",
      "Total training time: 1.45 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692967\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3750000, Avg. loss: 0.692963\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.50 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 2.79 seconds.\n",
      "Convergence after 6 epochs took 2.79 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000465, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 2.01 seconds.\n",
      "Convergence after 6 epochs took 2.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000572, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 6 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 2250000, Avg. loss: 0.692938\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000599, T: 4500000, Avg. loss: 0.692923\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.61 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000490, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.73 seconds.\n",
      "Convergence after 6 epochs took 1.73 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.52 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000482, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000580, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000600, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.87 seconds.\n",
      "Convergence after 6 epochs took 1.87 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000472, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692968\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693003\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.80 seconds.\n",
      "Convergence after 6 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000483, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.21 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 750000, Avg. loss: 0.692979\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692953\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 3000000, Avg. loss: 0.692937\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692929\n",
      "Total training time: 1.39 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 750000, Avg. loss: 0.692977\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.87 seconds.\n",
      "Convergence after 6 epochs took 1.87 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692955\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000494, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 2.11 seconds.\n",
      "Convergence after 6 epochs took 2.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000525, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 2250000, Avg. loss: 0.692941\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000597, T: 4500000, Avg. loss: 0.692926\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 6 epochs took 1.36 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 750000, Avg. loss: 0.692973\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 1500000, Avg. loss: 0.692947\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 2250000, Avg. loss: 0.692937\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3000000, Avg. loss: 0.692931\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000592, T: 3750000, Avg. loss: 0.692926\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000602, T: 4500000, Avg. loss: 0.692922\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000463, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692980\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692972\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692966\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692962\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692959\n",
      "Total training time: 1.80 seconds.\n",
      "Convergence after 6 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000480, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000473, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000505, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000524, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 2.32 seconds.\n",
      "Convergence after 6 epochs took 2.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 2250000, Avg. loss: 0.692943\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3750000, Avg. loss: 0.692932\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000591, T: 4500000, Avg. loss: 0.692928\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000597, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.43 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000475, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.52 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000455, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 1500000, Avg. loss: 0.692983\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000506, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 3000000, Avg. loss: 0.692969\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3750000, Avg. loss: 0.692965\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 4500000, Avg. loss: 0.692962\n",
      "Total training time: 1.18 seconds.\n",
      "Convergence after 6 epochs took 1.18 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000481, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000556, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 6 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000464, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.83 seconds.\n",
      "Convergence after 6 epochs took 1.83 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 2250000, Avg. loss: 0.692938\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000583, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 3750000, Avg. loss: 0.692927\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000603, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 6 epochs took 1.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692976\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 1500000, Avg. loss: 0.692950\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000574, T: 3000000, Avg. loss: 0.692934\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000594, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 6 epochs took 1.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000457, T: 750000, Avg. loss: 0.693005\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 1500000, Avg. loss: 0.692982\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 2250000, Avg. loss: 0.692974\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 4500000, Avg. loss: 0.692961\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000494, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000526, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000537, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000479, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.49 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000565, T: 2250000, Avg. loss: 0.692940\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 3750000, Avg. loss: 0.692929\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000599, T: 4500000, Avg. loss: 0.692925\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.95 seconds.\n",
      "Convergence after 6 epochs took 1.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 6 epochs took 1.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000459, T: 750000, Avg. loss: 0.693004\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692981\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692973\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692968\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3750000, Avg. loss: 0.692964\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692960\n",
      "Total training time: 1.82 seconds.\n",
      "Convergence after 6 epochs took 1.82 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000484, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000462, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000495, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.00 seconds.\n",
      "Convergence after 6 epochs took 2.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000538, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000573, T: 3000000, Avg. loss: 0.692936\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000584, T: 3750000, Avg. loss: 0.692931\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.75 seconds.\n",
      "Convergence after 6 epochs took 1.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000581, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 2.02 seconds.\n",
      "Convergence after 6 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000468, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000519, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.33 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 750000, Avg. loss: 0.692993\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692970\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 2250000, Avg. loss: 0.692962\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3000000, Avg. loss: 0.692956\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 3750000, Avg. loss: 0.692952\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.35 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000458, T: 750000, Avg. loss: 0.693002\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000491, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.26 seconds.\n",
      "Convergence after 6 epochs took 1.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000480, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000512, T: 1500000, Avg. loss: 0.692972\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000531, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3000000, Avg. loss: 0.692958\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000564, T: 4500000, Avg. loss: 0.692950\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000513, T: 750000, Avg. loss: 0.692974\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 1500000, Avg. loss: 0.692948\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000582, T: 3000000, Avg. loss: 0.692932\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000593, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000602, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.56 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000515, T: 750000, Avg. loss: 0.692972\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000550, T: 1500000, Avg. loss: 0.692946\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000570, T: 2250000, Avg. loss: 0.692936\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000585, T: 3000000, Avg. loss: 0.692929\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000596, T: 3750000, Avg. loss: 0.692925\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000605, T: 4500000, Avg. loss: 0.692921\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000477, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000509, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000528, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000560, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.33 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000485, T: 750000, Avg. loss: 0.692995\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000517, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000549, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692997\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692974\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692966\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 3000000, Avg. loss: 0.692960\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692956\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692953\n",
      "Total training time: 1.41 seconds.\n",
      "Convergence after 6 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000477, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000510, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000529, T: 2250000, Avg. loss: 0.692964\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000542, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 3750000, Avg. loss: 0.692954\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000561, T: 4500000, Avg. loss: 0.692951\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000503, T: 1500000, Avg. loss: 0.692975\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000522, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692961\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000546, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 2.17 seconds.\n",
      "Convergence after 6 epochs took 2.17 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000489, T: 750000, Avg. loss: 0.692983\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 1500000, Avg. loss: 0.692957\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 2250000, Avg. loss: 0.692948\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000558, T: 3000000, Avg. loss: 0.692941\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 3750000, Avg. loss: 0.692937\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 4500000, Avg. loss: 0.692933\n",
      "Total training time: 1.97 seconds.\n",
      "Convergence after 6 epochs took 1.97 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 1500000, Avg. loss: 0.692952\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000569, T: 3000000, Avg. loss: 0.692935\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000580, T: 3750000, Avg. loss: 0.692930\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000590, T: 4500000, Avg. loss: 0.692927\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000465, T: 750000, Avg. loss: 0.693001\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000497, T: 1500000, Avg. loss: 0.692979\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000516, T: 2250000, Avg. loss: 0.692971\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 3000000, Avg. loss: 0.692965\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3750000, Avg. loss: 0.692961\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000548, T: 4500000, Avg. loss: 0.692958\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000476, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000508, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000527, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000540, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000551, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000559, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000478, T: 750000, Avg. loss: 0.692996\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000511, T: 1500000, Avg. loss: 0.692973\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000530, T: 2250000, Avg. loss: 0.692965\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3000000, Avg. loss: 0.692959\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000554, T: 3750000, Avg. loss: 0.692955\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 4500000, Avg. loss: 0.692952\n",
      "Total training time: 2.05 seconds.\n",
      "Convergence after 6 epochs took 2.05 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.692999\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000534, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000544, T: 3750000, Avg. loss: 0.692957\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.82 seconds.\n",
      "Convergence after 6 epochs took 1.82 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 750000, Avg. loss: 0.692992\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692969\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3000000, Avg. loss: 0.692955\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 2.10 seconds.\n",
      "Convergence after 6 epochs took 2.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000499, T: 750000, Avg. loss: 0.692980\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 1500000, Avg. loss: 0.692954\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 2250000, Avg. loss: 0.692944\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000568, T: 3000000, Avg. loss: 0.692938\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000579, T: 3750000, Avg. loss: 0.692933\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000588, T: 4500000, Avg. loss: 0.692929\n",
      "Total training time: 1.68 seconds.\n",
      "Convergence after 6 epochs took 1.68 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000507, T: 750000, Avg. loss: 0.692975\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000541, T: 1500000, Avg. loss: 0.692949\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000562, T: 2250000, Avg. loss: 0.692939\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000576, T: 3000000, Avg. loss: 0.692933\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 3750000, Avg. loss: 0.692928\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000597, T: 4500000, Avg. loss: 0.692924\n",
      "Total training time: 1.99 seconds.\n",
      "Convergence after 6 epochs took 1.99 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000470, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000502, T: 1500000, Avg. loss: 0.692977\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000521, T: 2250000, Avg. loss: 0.692969\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 3000000, Avg. loss: 0.692963\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000545, T: 3750000, Avg. loss: 0.692959\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000553, T: 4500000, Avg. loss: 0.692956\n",
      "Total training time: 1.34 seconds.\n",
      "Convergence after 6 epochs took 1.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000469, T: 750000, Avg. loss: 0.693000\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000501, T: 1500000, Avg. loss: 0.692978\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 2250000, Avg. loss: 0.692970\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 3000000, Avg. loss: 0.692964\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000543, T: 3750000, Avg. loss: 0.692960\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 4500000, Avg. loss: 0.692957\n",
      "Total training time: 2.04 seconds.\n",
      "Convergence after 6 epochs took 2.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000471, T: 750000, Avg. loss: 0.692998\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000504, T: 1500000, Avg. loss: 0.692976\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000523, T: 2250000, Avg. loss: 0.692967\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000536, T: 3000000, Avg. loss: 0.692962\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3750000, Avg. loss: 0.692958\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 4500000, Avg. loss: 0.692954\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 6 epochs took 1.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000482, T: 750000, Avg. loss: 0.692994\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000514, T: 1500000, Avg. loss: 0.692971\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000533, T: 2250000, Avg. loss: 0.692963\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000547, T: 3000000, Avg. loss: 0.692957\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000557, T: 3750000, Avg. loss: 0.692953\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000566, T: 4500000, Avg. loss: 0.692949\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000487, T: 750000, Avg. loss: 0.692992\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000520, T: 1500000, Avg. loss: 0.692969\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000539, T: 2250000, Avg. loss: 0.692961\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 3000000, Avg. loss: 0.692955\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000563, T: 3750000, Avg. loss: 0.692951\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000571, T: 4500000, Avg. loss: 0.692948\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000498, T: 750000, Avg. loss: 0.692980\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000532, T: 1500000, Avg. loss: 0.692954\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000552, T: 2250000, Avg. loss: 0.692944\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000567, T: 3000000, Avg. loss: 0.692938\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000578, T: 3750000, Avg. loss: 0.692933\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000587, T: 4500000, Avg. loss: 0.692930\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000500, T: 750000, Avg. loss: 0.692978\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000535, T: 1500000, Avg. loss: 0.692951\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 8, Bias: -0.000555, T: 2250000, Avg. loss: 0.692942\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m SGD_clf_ada \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(),AdaBoostClassifier(estimator\u001b[38;5;241m=\u001b[39mSGDClassifier(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.01\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m SGD_clf_ada\u001b[38;5;241m.\u001b[39mfit(X,y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:169\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    166\u001b[0m sample_weight[zero_weight_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost(\n\u001b[0;32m    170\u001b[0m     iboost, X, y, sample_weight, random_state\n\u001b[0;32m    171\u001b[0m )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:594\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \n\u001b[0;32m    557\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:605\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[0;32m    603\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m--> 605\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    607\u001b[0m y_predict_proba \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:938\u001b[0m, in \u001b[0;36mBaseSGDClassifier.fit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m    Returns an instance of self.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[1;32m--> 938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    939\u001b[0m     X,\n\u001b[0;32m    940\u001b[0m     y,\n\u001b[0;32m    941\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    942\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    943\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss,\n\u001b[0;32m    944\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[0;32m    945\u001b[0m     coef_init\u001b[38;5;241m=\u001b[39mcoef_init,\n\u001b[0;32m    946\u001b[0m     intercept_init\u001b[38;5;241m=\u001b[39mintercept_init,\n\u001b[0;32m    947\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    948\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:725\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m--> 725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[0;32m    726\u001b[0m     X,\n\u001b[0;32m    727\u001b[0m     y,\n\u001b[0;32m    728\u001b[0m     alpha,\n\u001b[0;32m    729\u001b[0m     C,\n\u001b[0;32m    730\u001b[0m     loss,\n\u001b[0;32m    731\u001b[0m     learning_rate,\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m    733\u001b[0m     classes,\n\u001b[0;32m    734\u001b[0m     sample_weight,\n\u001b[0;32m    735\u001b[0m     coef_init,\n\u001b[0;32m    736\u001b[0m     intercept_init,\n\u001b[0;32m    737\u001b[0m )\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m    743\u001b[0m ):\n\u001b[0;32m    744\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    745\u001b[0m         (\n\u001b[0;32m    746\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iteration reached before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    750\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    751\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:649\u001b[0m, in \u001b[0;36mBaseSGDClassifier._partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# delegate to concrete training procedure\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_multiclass(\n\u001b[0;32m    650\u001b[0m         X,\n\u001b[0;32m    651\u001b[0m         y,\n\u001b[0;32m    652\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[0;32m    653\u001b[0m         C\u001b[38;5;241m=\u001b[39mC,\n\u001b[0;32m    654\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    655\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    656\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[0;32m    657\u001b[0m     )\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n_classes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_binary(\n\u001b[0;32m    660\u001b[0m         X,\n\u001b[0;32m    661\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    666\u001b[0m         max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[0;32m    667\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:804\u001b[0m, in \u001b[0;36mBaseSGDClassifier._fit_multiclass\u001b[1;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m    802\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    803\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n\u001b[1;32m--> 804\u001b[0m result \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    805\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, require\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msharedmem\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    806\u001b[0m )(\n\u001b[0;32m    807\u001b[0m     delayed(fit_binary)(\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    809\u001b[0m         i,\n\u001b[0;32m    810\u001b[0m         X,\n\u001b[0;32m    811\u001b[0m         y,\n\u001b[0;32m    812\u001b[0m         alpha,\n\u001b[0;32m    813\u001b[0m         C,\n\u001b[0;32m    814\u001b[0m         learning_rate,\n\u001b[0;32m    815\u001b[0m         max_iter,\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expanded_class_weight[i],\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    818\u001b[0m         sample_weight,\n\u001b[0;32m    819\u001b[0m         validation_mask\u001b[38;5;241m=\u001b[39mvalidation_mask,\n\u001b[0;32m    820\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    821\u001b[0m     )\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seeds)\n\u001b[0;32m    823\u001b[0m )\n\u001b[0;32m    825\u001b[0m \u001b[38;5;66;03m# take the maximum of n_iter_ over every binary fit\u001b[39;00m\n\u001b[0;32m    826\u001b[0m n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:463\u001b[0m, in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    460\u001b[0m tol \u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;28;01mif\u001b[39;00m est\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[0;32m    462\u001b[0m _plain_sgd \u001b[38;5;241m=\u001b[39m _get_plain_sgd_function(input_dtype\u001b[38;5;241m=\u001b[39mcoef\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 463\u001b[0m coef, intercept, average_coef, average_intercept, n_iter_ \u001b[38;5;241m=\u001b[39m _plain_sgd(\n\u001b[0;32m    464\u001b[0m     coef,\n\u001b[0;32m    465\u001b[0m     intercept,\n\u001b[0;32m    466\u001b[0m     average_coef,\n\u001b[0;32m    467\u001b[0m     average_intercept,\n\u001b[0;32m    468\u001b[0m     est\u001b[38;5;241m.\u001b[39m_loss_function_,\n\u001b[0;32m    469\u001b[0m     penalty_type,\n\u001b[0;32m    470\u001b[0m     alpha,\n\u001b[0;32m    471\u001b[0m     C,\n\u001b[0;32m    472\u001b[0m     est\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[0;32m    473\u001b[0m     dataset,\n\u001b[0;32m    474\u001b[0m     validation_mask,\n\u001b[0;32m    475\u001b[0m     est\u001b[38;5;241m.\u001b[39mearly_stopping,\n\u001b[0;32m    476\u001b[0m     validation_score_cb,\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mint\u001b[39m(est\u001b[38;5;241m.\u001b[39mn_iter_no_change),\n\u001b[0;32m    478\u001b[0m     max_iter,\n\u001b[0;32m    479\u001b[0m     tol,\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28mint\u001b[39m(est\u001b[38;5;241m.\u001b[39mfit_intercept),\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28mint\u001b[39m(est\u001b[38;5;241m.\u001b[39mverbose),\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28mint\u001b[39m(est\u001b[38;5;241m.\u001b[39mshuffle),\n\u001b[0;32m    483\u001b[0m     seed,\n\u001b[0;32m    484\u001b[0m     pos_weight,\n\u001b[0;32m    485\u001b[0m     neg_weight,\n\u001b[0;32m    486\u001b[0m     learning_rate_type,\n\u001b[0;32m    487\u001b[0m     est\u001b[38;5;241m.\u001b[39meta0,\n\u001b[0;32m    488\u001b[0m     est\u001b[38;5;241m.\u001b[39mpower_t,\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    490\u001b[0m     est\u001b[38;5;241m.\u001b[39mt_,\n\u001b[0;32m    491\u001b[0m     intercept_decay,\n\u001b[0;32m    492\u001b[0m     est\u001b[38;5;241m.\u001b[39maverage,\n\u001b[0;32m    493\u001b[0m )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m est\u001b[38;5;241m.\u001b[39maverage:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(est\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32msklearn\\\\linear_model\\\\_sgd_fast.pyx:640\u001b[0m, in \u001b[0;36msklearn.linear_model._sgd_fast._plain_sgd64\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1877\u001b[0m, in \u001b[0;36m_nonzero_dispatcher\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1873\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1874\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m asanyarray(a)\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m-> 1877\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_nonzero_dispatcher\u001b[39m(a):\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1881\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nonzero_dispatcher)\n\u001b[0;32m   1882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnonzero\u001b[39m(a):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SGD_clf_ada = make_pipeline(StandardScaler(),AdaBoostClassifier(estimator=SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000,verbose=True),n_estimators=500))\n",
    "SGD_clf_ada.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c5bce-8700-44e7-b4af-bc69ba2b52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_score(estimator,X,y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f77f448c-5630-4031-9046-01bf29cc5acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;sgdclassifier&#x27;,\n",
       "                 SGDClassifier(alpha=0.01, loss=&#x27;log_loss&#x27;, max_iter=2000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;sgdclassifier&#x27;,\n",
       "                 SGDClassifier(alpha=0.01, loss=&#x27;log_loss&#x27;, max_iter=2000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(alpha=0.01, loss=&#x27;log_loss&#x27;, max_iter=2000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier',\n",
       "                 SGDClassifier(alpha=0.01, loss='log_loss', max_iter=2000))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf = make_pipeline(StandardScaler(),SGDClassifier(loss='log_loss', alpha=.01,max_iter=2000))\n",
    "SGD_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33f72957-43bd-406e-a02d-11a455158d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46046"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = SGD_clf.predict_proba(X_test)\n",
    "in_top_three_scoring(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39e1d1a6-dba2-4570-9f4b-84f8cf6b34bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fertilizer Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750000</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750001</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750002</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750003</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750004</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>14-35-14 10-26-26 Urea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fertilizer Name\n",
       "id                            \n",
       "750000  14-35-14 10-26-26 Urea\n",
       "750001  14-35-14 10-26-26 Urea\n",
       "750002  14-35-14 10-26-26 Urea\n",
       "750003  14-35-14 10-26-26 Urea\n",
       "750004  14-35-14 10-26-26 Urea\n",
       "...                        ...\n",
       "999995  14-35-14 10-26-26 Urea\n",
       "999996  14-35-14 10-26-26 Urea\n",
       "999997  14-35-14 10-26-26 Urea\n",
       "999998  14-35-14 10-26-26 Urea\n",
       "999999  14-35-14 10-26-26 Urea\n",
       "\n",
       "[250000 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample_submission.csv\",index_col=0)\n",
    "test = pd.read_csv(\"test.csv\",index_col=0)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99d781a2-1833-4c4f-9fe2-b7173f5814c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temparature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Moisture</th>\n",
       "      <th>Soil Type</th>\n",
       "      <th>Crop Type</th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Phosphorous</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750000</th>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750001</th>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750002</th>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750003</th>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750004</th>\n",
       "      <td>31</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>36</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>35</td>\n",
       "      <td>63</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temparature  Humidity  Moisture  Soil Type  Crop Type  Nitrogen  \\\n",
       "id                                                                        \n",
       "750000           31        70        52          4         10        34   \n",
       "750001           27        62        45          3          8        30   \n",
       "750002           28        72        28          1          2        14   \n",
       "750003           37        53        57          0          2        18   \n",
       "750004           31        55        32          3          7        13   \n",
       "...             ...       ...       ...        ...        ...       ...   \n",
       "999995           26        66        30          3          8        14   \n",
       "999996           33        62        55          3          7        28   \n",
       "999997           36        53        64          0          6        28   \n",
       "999998           36        67        26          1          6        33   \n",
       "999999           35        63        36          1          2        29   \n",
       "\n",
       "        Potassium  Phosphorous  \n",
       "id                              \n",
       "750000         11           24  \n",
       "750001         14           15  \n",
       "750002         15            4  \n",
       "750003         17           36  \n",
       "750004         19           14  \n",
       "...           ...          ...  \n",
       "999995          7           18  \n",
       "999996         14            7  \n",
       "999997         11           27  \n",
       "999998          0           10  \n",
       "999999          2           13  \n",
       "\n",
       "[250000 rows x 8 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Soil Type'] = soil_encoder.transform(test['Soil Type'])\n",
    "test['Crop Type'] = crop_encoder.transform(test['Crop Type'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1185460e-27a6-44e4-aeec-298168dbaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = SGD_clf.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cebba608-48e4-463d-8255-4c11e29d73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(x):\n",
    "    return fert_encoder.classes_[x]\n",
    "vectorized_mapper = np.vectorize(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20c529b3-7cb7-4981-b638-fc06414b8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred\n",
    "y_test_pred_top3 = np.flip(np.argsort(y_test_pred, axis=1)[:, -3:], axis=1)\n",
    "y_test_pred_top3\n",
    "y_test_pred_strings = vectorized_mapper(y_test_pred_top3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c76a26ba-4a56-4845-af7b-37a1b74a2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20-20 10-26-26 28-28', '10-26-26 17-17-17 20',\n",
       "       '17-17-17 10-26-26 20', ..., '14-35-14 10-26-26 20',\n",
       "       '17-17-17 10-26-26 14', '14-35-14 17-17-17 10'], dtype='<U20')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = np.apply_along_axis(\" \".join, arr=y_test_pred_strings, axis=1)\n",
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce5356b0-1d68-4234-aebd-36ccffa0badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Fertilizer Name']= aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5401537c-e273-4bcb-89dc-98f9681c3412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['20-20', '10-26-26', '28-28'],\n",
       "       ['10-26-26', '17-17-17', '20-20']], dtype='<U8')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorized_mapper(np.flip(np.argsort(SGD_clf.predict_proba(test.iloc[:2]), axis=1)[:, -3:], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a80e928c-49b0-479c-9f15-e96cf4283299",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"attempt1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
